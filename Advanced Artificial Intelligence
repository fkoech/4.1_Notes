
CMT 440
--------------
Machine Learning 
---------------------
-The easy availability of high performance computing(HPC) has resulted in 
 a sudden increase demand for IT professionals having machine learning 
 skills.
 
 Objective of the course
 -------------------------------
 1.What is the crux of machine learning?
 2.What are the different types of machine learning?
 3.What are the different algorithms available for developing machine
  learning models?
 4.What  tools are available for developing these models?
 7.What are the programming choices?
 8.What platform support developement and deployment of machine learning application
 9.What IDES (Integrated developement Evironment) are available.
 10.How to upgrade your skills to this important area.
 
 
 What AI can do
 --------------------
 -Taging a face in a facebook photo.
 -AI that is  running behind the scenes and identifying faces 
 -Automous cars running on roads detect object in real time to steer the car.
 -Object detection technic in real time helps to learn the real-time traffic situation and 
 follow the best path(Google direction)
 -Google translator, helps in communications.
 
 -The advantange of AI is that it can it can perform extremely complex
 jobs with a great accuracy and speed.
 -For example the google direction suggest the fastest path to our destination that time instance.
 -It can judge the traffic situation in every possible path to give
  you a travel time estimate for each such path.
 -Alot of AI and machine learning techniques are in-use under the hoods of  google
 direction so that it can cover the entire globe.
 
 Statistical techniques that are used  for developing AI applications
 -------------------------------------------------------------------------
 -Regression
 -Classification
 -Clustering
 -Probabilities Theories
 -Decision trees
 -Satistical techniques  is used to develop AI with limited data.
 -Advanced methods such as the deep lerning can solve the many complex problems.
 
      What is machine learning
      --------------------------
 -Machine learning  is like an act of using the statistical optimazation techniques to  find out the equation 
 for the best curve.
 -It uses the optimazation technique to find the solution to problem.
       
       Categories of machine learning
       --------------------------------
 -Supervised learning (sl)
 -Unsupervised learning( ul)
 -Reinforcement leaning(rl)
 -Deep learning(dl)
 -Deep reinforcement learning (drl)
 
 
 ->ul - machine is made to learn on its own without any supervision.
 ->sl - ie the case of  housing price prediction.
 ->dl - human brain is simulated  in the artificial neural network(ANN) created in binary computers.
 -Machine learn on its own using the high computing power and huge memory resources that are available today.
 
 
 
 Growth of machine learning 
 --------------------------------
 -Speech recognition,  natural language processing.
 -Computer vision
 -Medical outcome analysis
 -Robot control
 -Computational biology
 -Sensor networks.
 
 -Trending - Big data
             Improved machine learning algorithms
             faster computers
             Good open-source software.
             
 Supervised learning
 -----------------------
 -Uses analogous to training a child to walk.
 
 Regression
 -------------
 -Similar to supervised learning, accept  that you give a concrete known examples to the
  computer.
  
  Classification 
  ---------------
  -You classify objects of similar nature into a single groups.
  
  Unsupervised learning
  ---------------------
  -Do not  specify a target variable to the machine, rather we ask machine what it can tell about a
  specific object.
  -To reach at this point the is a large number  of dataset  points that  the machine would require to 
  deduce .
  -For the case of supervised a machine need to be trained with even few thousands of data points.
  -For the cause of unsupervised learning, the number of data point that is reasonable 
   accepted for learning start in a few millions.
   -data ideally requires  curating.
   -Data Curating - is the organisation and integration  of data collection from various source.
                  - It involve annotation, publication and presentation of data such that the value of the data is maintained over time.
                    and data remains available  for reuse and preservation.
                    
 Reinforcement learning 
 ----------------------
 -Initially developed for machine to play Games.
 -The machine is given an algorithm  to analyze all possible moves at each  stage of the game.
 -The machine can select one of the move at random.
 -If the move is right,  the machine is rewarded, otherwise it may be penalized.
 -Slowly the machine started differenciating between right and wrong moves.
 -After a several iteration it started it would learn to solve the game puzzle with a better accuracy.
 -The accuracy of winning the game would improve as  the machine plays more and more games.
 
 
 How does the supervised learning different from the  reinforcement learning 
 ------------------------------------------------------------------------------
 -Reinforcement learning need not supply the labelled input/output pairs.
  their focus is on finding the  the balance  betweeen exploring new solution verse exploiting the
  learned  solution.
  
  
  
  DEEP LEARNING
  ---------------------
  -A model based on Artificial Neural  Network(ANN),  more specifically,
   convolution  neural networks(CNN),.
  -It used architectures such as:
                                 Deep neural network
                                 Deep belief network
                                 Recurrent neural network
                                 convolution neural network.
  -This networks have been successfully applied in  solving the problems of:
                               computer vision
                               speech recognition
                               natural language processing
                               bioinformatic
                               drug design
                               medical image analysis
                               games
 -Requires huge processing power and humongous data.
 
 
 Deep reinforcement learning
 ---------------------------------
 -Combines the techinques of both deep  and reiforcement learning.
 -Reiforcement learning algorithm like Q-like are now combined with  deep learning  to create a powerful DRL model.
 -It has been with great success in fields such as:
                                   Robotics
                                   Video Games
                                   Finance
                                   Healthcare
                                   
                                   
                                   
                                   
                                   
      Application  ares of machine learning
      -------------------------------------------
      -Traffic alerts
      -Social media
      -transport and commuting
      -Products recommendations
      -Virtual  personal assistant
      -self driving cars
      -Dynamic pricing
      -Google Translate
      -Online Video streaming
      -Fraud Detection.
      
      
      Social media(FACEBOOK)
      ---------------------------
      -Automatic friend tagging suggestions.
      -It uses face detection and image recognition to autmatically find the face of the person which 
      matches its' database and hence suggests for us to tag that person based on Deepface.
      -Deep learning is responsible for  recognistion of the faces and identifying which person 
       is in the picture. 
      -It also provides an alternative tag.
      
      
      Transportation and commuting(Uber)
      ----------------------------------------
      -For the case of booking a cab.
      -It  provides  a personalized application which is unique  to you.
      -It automatically detects your locations. 
      -It also provide options to either go home  or office or any other frequent place based on your History or pattern.
      -Is uses machine learning algorithms layered on top of historic trips data to make more accurate ETA prediction.
      
      Production Recommendation 
      ---------------------------------
      -Ads appearing across all you social media platform.
      -This happens beacuse google tracks your search mhistory and recommends ads based on your search history.
      
      Virtual personal assistants
      ------------------------------
      -Helps in finding useful information , when asked via text or voice.
      -Major applications of  machine learning 
                    Speech  recognition
                    Speech to text conversion
                    Natural language processing.
                    Text to speech conversion
     -Examples are:
                   siri, Alexa, google, cortana
                                 
 
 
 Traditional AI
 --------------------
 
 
 
       CHAPTER 2
       ------------------
   -Machine learning 
   ------------------------
   -ML - is a collection of algorithms and techniques used to build system that learns from data.
   -Then the system can then perform prediction by finding pattern in the data.
   -It sweeps traditional programming in  a certain cases.
   
   
   Difference between machine learning and traditional programming 
   ----------------------------------------------------------------------
   Traditional programming                                        machine learnig 
   -------------------------------------------------------------------------------
   1.data and the program produces the output       1.data and the output produces the program
   -----------------------------------------------------------------------------------------------
   2.Is a manual process                             2.Algorith automatical formulate the rules from the data
    (programmer manual formulate or code the rules)    
   ---------------------------------------------------------------------------------------------------------------------
   3.
 
 Machine learning composses of the following descipline;
      scientific computing
      mathematics
      statistics
      
      
      
      Why machine learning 
      -----------------------------
  -E-mail filter program  without using ml step by step
     1.identify how the spam email looks like.
     2.write algorithm to detect the pattern that you have seen.
     3.test the program and then make changes to the program until the results are good enough.
      -THe software flag woud flag the email as spam if certain numbers of those pattern are detected
      -if the case requires a long list of rules to find the solution it is suitable for ML to come in.
      -if in any case the email sender change email template, program need to update it manually.
      unlike the ML which will detect this automatically, and adapt to new data.
 
 When should you use machine learning 
 ---------------------------------------------
  -
  
  
  
              CHAPTER  2
              -----------------
Date processing in machine learning
-------------------------------------
-A process of preparing the raw  data and making it suitable for a machine learning model.
-First and crucial step while creating  a machine learning model.
-Faculitates the cleaning and formating of data.


Why do we need Data processing
-----------------------------------
-Real world data generally Contains noise, missing values and even unusable format which cannot be directly used by machine learning model.
-This will increase the efficiency  and accuracy of a machine learning model.
-It involve the following steps:
                     Getting the dataset
                     importing libraries
                      importing datasets
                      fnding missing data
                      Encoding categorical Data
                      splitting dataset into training and test set
                      Feature scaling.
                      
 
 
 
 Getting the datasets
 ----------------------
 -requires since a machine requires data to work.
 -Dataset - is a prober formated collection of data for a particular problem.
          -It may be of differnt format for differnt purpose.
          - should be put into a csv file in  order to use it our code(also HTML or xlsx file)
          
          
   What is a CSV file
   -----------------------
   -Stands for Comma-separated value.
   -It is a file format which allows us to save the tabular data, such as speedsheet.
   -It is useful for huge datasets used in programming.
   -Dataset can also be created by gathering data  using various API with python and should be put into .csv file.
   
   
   
  Importing libraries
  --------------------------
  -Used to perform specific jobs.
  -The specific libraries   used in data preprocessing:
              numpy - used for including any type of mathematical operation in the code.
                    - it is  a fundamental package for scientific calculation.
                    - support also adding large, multidimensional array  and matrics.
                    - import numpy as nm
         matplotlib - is a python 2D plotting library.
                    - With it we need to import a sub-library pyplot.
                    -used to plot any type of chart in python.
                    -import matplotlib.pyplot as mpt
       pandas   -  One of the most famous python library.
                -used to manage datasets.
                -It is an open-source data manipulation and analysis library.
                -import pandas as pd.
                
                
                
            importing the datasets
            -----------------------
   -procedure:
            import the datasets which we have collected  for our machine learning project.
            Before that set a working directory in spyder IDE.
            save your python file  in the directory which contains dataset
            Go to file explore option in spyder IDE, and select the required directory.
            Click on F5  button or run option to execute the file.
            n/b we can set any directory as a working directory, but must contain the required dataset.
            
   
   
   
   
   
   
   
   
   
   LESSON 3 01/01/2021
   ---------------------------
   Simple Linear regrassion in machine learning 
   --------------------------------------------------
   -A type of algorithm that model the relationship between a dependent variable and a single independent variable.
   -This relation is  linear or a sloped straight line, hence called simple linear regression.
   -It has two main objective:
            1.Model a relationship bewteen the two variable. - ie relationship between income and expenditure, experience and salaries.
            2.Forecasting new observations - ie weather forecasting according to temperature, revenue of a company according to the investment in a year.
            
    simple linear regression model
    ------------------------------------
    - Represented using the following equation:
               y = a0+a1x+ε 
    -a0 - is the intercept of the regression line.
    -a1 - is the slope od the regression line, it tells whether the line is icreasinf or decreasing.
    -ε  - is the term 
   
  
   
   
   Implementation of simple linear regresssion algorithm using python
   -------------------------------------------------------------------------
   -Take a dataset that has two variables.
   -Salary(dependant variable) and experience(independent variable)
   -The goal of the problems is to -find out if the is any relationship  between these two variables.
                                   -Find the best fit for the dataset.
                                   -How the depenfent  variables is changing by changing the dependent variable.
                                   
   -steps:
         1 - Data pre-processing 
         --------------------------
    -import the three important libraries, which will help us for loading the dataset,
     plot the graph, and create  the simple lenear regression model.
               import numpy as nm
               import matplotlib.pyplot as mtp
               import pandas as pd
   -load the dataset into our code.
               data_set = pd.read_csv('salary_Data.csv')
   -Execute the above line of code(ctrl+ENTER) 
   -read the dataset on our spyder IDE screen by clicking on the variable explorer option
   -It will show the data dataset which has two variables. salary and expence.
   -N/b floder containing the code file must be saved as a working directory and thedataset  or csv file should be in he same folder.
   -Extract the dependent and independent variables  form the given daaset.
   -the independent variable  is year of experience, and dependent variable is salary.
                 x = data_set.iloc[:,:-].values
                 y = data_set.iloc[:,1].values
   - -1 removes the last column from the dataset.
   -We can see the x (independent) variable and y(dependent) variable has been extracted from the given daaset.
   
   -We can spit dataset  so that we can train the model using a teaining dataset and ten test the 
    dataset 
                #spitting the dataset into training and test set.
                from sklearn.model_selection import train_test_split
                x_train, x_test, y_train, y_test = train_test_slit(x,y,test_size=1/3, random_state=0)
   -By executing above code, we ill get x-test, x-train and y-test, y-train dataset.
   -for simple linear regression, we will not use feature  scaling.Because python libraries take care of it for some cases.
   - The dataset  is well prepared to work on it and we are going to start building a simple linear regresssion  model for a given problem.
   
   2.Fitting the simple linear regression to the training set.
   --------------------------------------------------------------
   page 5
                
           
           
           
           Multiple Linear Regression
           ---------------------------
   - Variable is affected by more than one predictor variable.
   - An extension of Simple Linear regression as it takes more than one predictor variable to predict the response variable.
   - one of the important regression algorithms which models the linear relationship between a single dependent continuous
     variable and more than one independent variable.
   -Dependent or target variable(Y) must be the continuous/real, but the predictor or independent 
    variable may be of continuous or categorical form.
   -Each feature variable must model the linear relationship with the dependent variable.
   -Tries to fit a regression line through a multidimensional space of data-points.
          

Assumptions for Multiple Linear Regression
----------------------------------------------
-A linear relationship should exist between the Target and predictor variables.
-The regression residuals must be normally distributed.
-MLR assumes little or no multicollinearity (correlation between the independent variable) in data.

Implementation of Multiple Linear Regression model using Python:
------------------------------------------------------------------
-Problem Description:
We have a dataset of 50 start-up companies.
This dataset contains five main information: R&D Spend,
Administration Spend, Marketing Spend, State, and Profit for a financial year.
Our goal is to create a model that can easily determine which company has a maximum profit,
and which is the most affecting factor for the profit of a company.

-Since we need to find the Profit, so it is the dependent variable,
and the other four variables are independent variables.
Below are the main steps of deploying the MLR model:
    1.Data Pre-processing Steps
    2.Fitting the MLR model to the training set
    3.Predicting the result of the test set
    
-Step-1: Data Pre-processing Step:
   contains the below steps:
Importing libraries: Firstly we will import the library which will help in building the model.
Below is the code for it:
     1.# importing libraries  
     2.import numpy as nm  
     3.import matplotlib.pyplot as mtp  
     4.import pandas as pd  
 Importing dataset: Now we will import the dataset(50_CompList), which contains all the variables.
Below is the code for it:
        1.#importing datasets  
        data_set= pd.read_csv('50_CompList.csv')
        #there are five variables, in which four variables are continuous and 
        #one is categorical variable
 Extracting dependent and independent Variables:
     1.#Extracting Independent and dependent Variable  
     2.x= data_set.iloc[:, :-1].values  
     3.y= data_set.iloc[:, 4].values    
Encoding Dummy Variables
 -To encode the categorical variable into numbers, we will use the LabelEncoder class.
 But it is not sufficient because it still has some relational order, which may create a wrong model.
 So in order to remove this problem, we will use OneHotEncoder,
 which will create the dummy variables.
            1.#Catgorical data  
            2.from sklearn.preprocessing import LabelEncoder, OneHotEncoder  
            3.labelencoder_x= LabelEncoder()  
            4.x[:, 3]= labelencoder_x.fit_transform(x[:,3])  
            5.onehotencoder= OneHotEncoder(categorical_features= [3])    
            6.x= onehotencoder.fit_transform(x).toarray()  
  
     
